{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca6633a6-cdcd-4e90-8abd-9d4fe8f2846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open goldlabels and predictions from SVM on dev set (best feature selection)\n",
    "error_inputfile = 'results/pred_gold_dev.csv'\n",
    "gold_pred_df = pd.read_csv(error_inputfile, sep=\"\\t\")\n",
    "goldlabels = error_table['gold'].tolist()\n",
    "predictions = error_table['pred'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26e5d331-2ba6-4d23-9bfb-4cc4ea026a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open .txt file to easily extract tokens\n",
    "inputfile = 'data/SEM-2012-SharedTask-CD-SCO-dev-simple.v2.txt'\n",
    "df = pd.read_csv(inputfile, sep=\"\\t\", header=None, names=[\"Book\", \"Sent nr\", \"Token nr\", \"Token\", \"Label\"])\n",
    "tokenlist = df['Token'].tolist()\n",
    "realsents = df['Sent nr'].tolist()\n",
    "tokennrs = df['Token nr'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ed24fd4-8269-44d6-8413-211f1acc0209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new sentence numbers\n",
    "i = 0\n",
    "sentnrs = []\n",
    "\n",
    "for nr in tokennrs:\n",
    "    if nr == 0:\n",
    "        i += 1\n",
    "    sentnrs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3eeb2797-c471-43d6-8855-cc8eccab78dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent nr</th>\n",
       "      <th>newsent nr</th>\n",
       "      <th>token nr</th>\n",
       "      <th>token</th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Singular</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Experience</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13562</th>\n",
       "      <td>439</td>\n",
       "      <td>787</td>\n",
       "      <td>9</td>\n",
       "      <td>orthodox</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13563</th>\n",
       "      <td>439</td>\n",
       "      <td>787</td>\n",
       "      <td>10</td>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13564</th>\n",
       "      <td>439</td>\n",
       "      <td>787</td>\n",
       "      <td>11</td>\n",
       "      <td>his</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13565</th>\n",
       "      <td>439</td>\n",
       "      <td>787</td>\n",
       "      <td>12</td>\n",
       "      <td>ritual</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13566</th>\n",
       "      <td>439</td>\n",
       "      <td>787</td>\n",
       "      <td>13</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13567 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sent nr  newsent nr  token nr       token true pred\n",
       "0            0           1         0          1.    O    O\n",
       "1            0           1         1         The    O    O\n",
       "2            0           1         2    Singular    O    O\n",
       "3            0           1         3  Experience    O    O\n",
       "4            0           1         4          of    O    O\n",
       "...        ...         ...       ...         ...  ...  ...\n",
       "13562      439         787         9    orthodox    O    O\n",
       "13563      439         787        10          in    O    O\n",
       "13564      439         787        11         his    O    O\n",
       "13565      439         787        12      ritual    O    O\n",
       "13566      439         787        13           .    O    O\n",
       "\n",
       "[13567 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all tokens, labels and predictions in dataframe\n",
    "d = {'sent nr': realsents, 'newsent nr': sentnrs, 'token nr': tokennrs, 'token': tokenlist, 'true': goldlabels, 'pred': predictions}\n",
    "error_analysis_df = pd.DataFrame(d)\n",
    "error_analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3af3683f-2dce-4877-a250-92135d6d0914",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_analysis_df.to_csv('error_analysis_df.csv', sep='\\t', header=True, quotechar='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69c15cc1-48a4-4cdc-a185-20ce6871baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all matches and errors together in lists\n",
    "matches = [[],[],[],[]]\n",
    "errors = [[],[],[],[]]\n",
    "i = 0\n",
    "for token in tokenlist:\n",
    "    if goldlabels[i] == predictions[i]:\n",
    "        matches[0].append(token)\n",
    "        matches[1].append(goldlabels[i])\n",
    "        matches[2].append(predictions[i])\n",
    "        matches[3].append(sentnrs[i])\n",
    "    if goldlabels[i] != predictions[i]:\n",
    "        errors[0].append(token)\n",
    "        errors[1].append(goldlabels[i])\n",
    "        errors[2].append(predictions[i]) \n",
    "        errors[3].append(sentnrs[i])\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8cec00e-188f-451a-b2ba-a68e3ffbc5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent nr</th>\n",
       "      <th>token</th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Singular</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Experience</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13548</th>\n",
       "      <td>787</td>\n",
       "      <td>orthodox</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13549</th>\n",
       "      <td>787</td>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13550</th>\n",
       "      <td>787</td>\n",
       "      <td>his</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13551</th>\n",
       "      <td>787</td>\n",
       "      <td>ritual</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13552</th>\n",
       "      <td>787</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13553 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sent nr       token true pred\n",
       "0            1          1.    O    O\n",
       "1            1         The    O    O\n",
       "2            1    Singular    O    O\n",
       "3            1  Experience    O    O\n",
       "4            1          of    O    O\n",
       "...        ...         ...  ...  ...\n",
       "13548      787    orthodox    O    O\n",
       "13549      787          in    O    O\n",
       "13550      787         his    O    O\n",
       "13551      787      ritual    O    O\n",
       "13552      787           .    O    O\n",
       "\n",
       "[13553 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe with all matches\n",
    "d = {'sent nr': matches[3], 'token': matches[0], 'true': matches[1], 'pred': matches[2]}\n",
    "matches_df = pd.DataFrame(d)\n",
    "matches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "117958fd-b199-482d-9973-6f7d51a8f9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent nr</th>\n",
       "      <th>token</th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>incredible</td>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>none</td>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>231</td>\n",
       "      <td>neither</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>238</td>\n",
       "      <td>no</td>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>249</td>\n",
       "      <td>by</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>249</td>\n",
       "      <td>means</td>\n",
       "      <td>I-NEG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>455</td>\n",
       "      <td>none</td>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>462</td>\n",
       "      <td>Save</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>524</td>\n",
       "      <td>none</td>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>587</td>\n",
       "      <td>nobody</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>668</td>\n",
       "      <td>without</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>706</td>\n",
       "      <td>never</td>\n",
       "      <td>O</td>\n",
       "      <td>B-NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>762</td>\n",
       "      <td>more</td>\n",
       "      <td>I-NEG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>766</td>\n",
       "      <td>not</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sent nr       token   true   pred\n",
       "0        18  incredible      O  B-NEG\n",
       "1        45        none      O  B-NEG\n",
       "2       231     neither  B-NEG      O\n",
       "3       238          no      O  B-NEG\n",
       "4       249          by  B-NEG      O\n",
       "5       249       means  I-NEG      O\n",
       "6       455        none      O  B-NEG\n",
       "7       462        Save  B-NEG      O\n",
       "8       524        none      O  B-NEG\n",
       "9       587      nobody  B-NEG      O\n",
       "10      668     without  B-NEG      O\n",
       "11      706       never      O  B-NEG\n",
       "12      762        more  I-NEG      O\n",
       "13      766         not  B-NEG      O"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe with all errors\n",
    "d = {'sent nr': errors[3], 'token': errors[0], 'true': errors[1], 'pred': errors[2]}\n",
    "errors_df = pd.DataFrame(d)\n",
    "errors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec24177f-75bb-45b9-b6ec-7adcd531d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get matches statistics\n",
    "prefixes = ['un', 'dis', 'im', 'in', 'non', 'ir']\n",
    "suffixes = ['less', 'lessly', 'lessness']\n",
    "\n",
    "matching_tokens = matches[0]\n",
    "matching_true = matches[1]\n",
    "matching_pred = matches[2]\n",
    "matching_sents = matches[3]\n",
    "\n",
    "affixes = [[],[],[]]\n",
    "lexicals = [[],[],[]]\n",
    "outsides = [[],[],[]]\n",
    "\n",
    "i = 0\n",
    "for token in matching_tokens:\n",
    "    if token.startswith('un') or token.startswith('dis') or token.startswith('im') or token.startswith('in') or token.startswith('non') or token.startswith('ir') or token.endswith('less') or token.endswith('lessly') or token.endswith('lessness'):\n",
    "        if matching_true[i] != 'O':\n",
    "            affixes[0].append(token)\n",
    "            affixes[1].append(matching_true[i])\n",
    "            affixes[2].append(matching_sents[i])\n",
    "        else:\n",
    "            outsides[0].append(token)\n",
    "            outsides[1].append(matching_true[i])\n",
    "            outsides[2].append(matching_sents[i])\n",
    "    else:\n",
    "        if matching_true[i] == 'O':\n",
    "            outsides[0].append(token)\n",
    "            outsides[1].append(matching_true[i])\n",
    "            outsides[2].append(matching_sents[i])\n",
    "        else:\n",
    "            lexicals[0].append(token)\n",
    "            lexicals[1].append(matching_true[i])\n",
    "            lexicals[2].append(matching_sents[i])\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b27a058a-dab8-4e0a-8733-373182565597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches O total: 13382\n",
      "Matches ALL NEGS affixal: 33\n",
      "Matches ALL NEGS lexical: 138\n"
     ]
    }
   ],
   "source": [
    "# stats\n",
    "print(f\"Matches O total: {len(outsides[0])}\")\n",
    "print(f\"Matches ALL NEGS affixal: {len(affixes[0])}\")\n",
    "print(f\"Matches ALL NEGS lexical: {len(lexicals[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dccb58f7-2704-4550-b624-9b5868d17b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches B-NEG affixal: 33\n",
      "Matches I-NEG affixal: 0\n"
     ]
    }
   ],
   "source": [
    "# more stats (affixal)\n",
    "b_neg_affix = []\n",
    "i_neg_affix = []\n",
    "\n",
    "i = 0\n",
    "for item in affixes[0]:\n",
    "    if affixes[1][i] == 'B-NEG':\n",
    "        b_neg_affix.append((item, affixes[1][i], affixes[2][i]))\n",
    "    elif affixes[1][i] == 'I-NEG':\n",
    "        i_neg_affix.append((item, affixes[1][i], affixes[2][i]))\n",
    "    i +=1\n",
    "\n",
    "print(f\"Matches B-NEG affixal: {len(b_neg_affix)}\")\n",
    "print(f\"Matches I-NEG affixal: {len(i_neg_affix)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b4751360-1ac6-42b4-9858-a19f16c4284a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unpleasant', 'B-NEG', 37),\n",
       " ('improper', 'B-NEG', 39),\n",
       " ('unbrushed', 'B-NEG', 52),\n",
       " ('unshaven', 'B-NEG', 52),\n",
       " ('unbrushed', 'B-NEG', 60),\n",
       " ('unkempt', 'B-NEG', 60),\n",
       " ('unconventional', 'B-NEG', 61),\n",
       " ('impatience', 'B-NEG', 122),\n",
       " ('unknown', 'B-NEG', 168),\n",
       " ('unburned', 'B-NEG', 184),\n",
       " ('undoubtedly', 'B-NEG', 207),\n",
       " ('uncommonly', 'B-NEG', 225),\n",
       " ('impossible', 'B-NEG', 246),\n",
       " ('unmistakable', 'B-NEG', 247),\n",
       " ('impossible', 'B-NEG', 249),\n",
       " ('impossible', 'B-NEG', 279),\n",
       " ('unnatural', 'B-NEG', 283),\n",
       " ('irreproachable', 'B-NEG', 304),\n",
       " ('insensibly', 'B-NEG', 310),\n",
       " ('inadmissable', 'B-NEG', 325),\n",
       " ('insufferable', 'B-NEG', 329),\n",
       " ('needless', 'B-NEG', 457),\n",
       " ('dissatisfied', 'B-NEG', 469),\n",
       " ('unknown', 'B-NEG', 535),\n",
       " ('inexplicable', 'B-NEG', 540),\n",
       " ('sapless', 'B-NEG', 559),\n",
       " ('undoubtedly', 'B-NEG', 560),\n",
       " ('dislike', 'B-NEG', 575),\n",
       " ('invisible', 'B-NEG', 614),\n",
       " ('unknown', 'B-NEG', 624),\n",
       " ('impossible', 'B-NEG', 625),\n",
       " ('fearless', 'B-NEG', 675),\n",
       " ('unclean', 'B-NEG', 784)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of tuples of correctly predicted affixal negation cues and their labels + new sentence numbers\n",
    "b_neg_affix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93b09628-ecbf-4c93-94c9-e452fefc2cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches B-NEG lexical: 137\n",
      "Matches I-NEG lexical: 1\n"
     ]
    }
   ],
   "source": [
    "# even more stats (lexical)\n",
    "b_neg_lex = []\n",
    "i_neg_lex = []\n",
    "\n",
    "i = 0\n",
    "for item in lexicals[0]:\n",
    "    if lexicals[1][i] == 'B-NEG':\n",
    "        b_neg_lex.append((item, lexicals[1][i], lexicals[2][i]))\n",
    "    elif lexicals[1][i] == 'I-NEG':\n",
    "        i_neg_lex.append((item, lexicals[1][i], lexicals[2][i]))\n",
    "    i +=1\n",
    "\n",
    "print(f\"Matches B-NEG lexical: {len(b_neg_lex)}\")\n",
    "print(f\"Matches I-NEG lexical: {len(i_neg_lex)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b141631-7948-4ccf-8cc0-473465283993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('no', 'B-NEG', 4),\n",
       " ('No', 'B-NEG', 24),\n",
       " ('not', 'B-NEG', 28),\n",
       " ('Never', 'B-NEG', 38),\n",
       " ('not', 'B-NEG', 44),\n",
       " ('not', 'B-NEG', 44),\n",
       " ('no', 'B-NEG', 45),\n",
       " ('not', 'B-NEG', 47),\n",
       " ('no', 'B-NEG', 51),\n",
       " ('without', 'B-NEG', 51),\n",
       " ('never', 'B-NEG', 54),\n",
       " ('not', 'B-NEG', 62),\n",
       " (\"n't\", 'B-NEG', 87),\n",
       " (\"n't\", 'B-NEG', 87),\n",
       " ('no', 'B-NEG', 96),\n",
       " ('no', 'B-NEG', 97),\n",
       " ('never', 'B-NEG', 97),\n",
       " ('neither', 'B-NEG', 123),\n",
       " ('nor', 'B-NEG', 123),\n",
       " ('not', 'B-NEG', 123),\n",
       " ('nothing', 'B-NEG', 126),\n",
       " ('no', 'B-NEG', 129),\n",
       " ('not', 'B-NEG', 132),\n",
       " ('no', 'B-NEG', 140),\n",
       " ('no', 'B-NEG', 144),\n",
       " ('no', 'B-NEG', 146),\n",
       " ('No', 'B-NEG', 150),\n",
       " ('never', 'B-NEG', 152),\n",
       " ('not', 'B-NEG', 165),\n",
       " ('nothing', 'B-NEG', 172),\n",
       " ('without', 'B-NEG', 191),\n",
       " ('nothing', 'B-NEG', 212),\n",
       " ('not', 'B-NEG', 215),\n",
       " ('nor', 'B-NEG', 215),\n",
       " ('no', 'B-NEG', 219),\n",
       " ('no', 'B-NEG', 222),\n",
       " ('nor', 'B-NEG', 222),\n",
       " ('No', 'B-NEG', 224),\n",
       " ('no', 'B-NEG', 224),\n",
       " ('nothing', 'B-NEG', 226),\n",
       " ('nor', 'B-NEG', 231),\n",
       " ('no', 'B-NEG', 238),\n",
       " ('no', 'B-NEG', 240),\n",
       " ('not', 'B-NEG', 251),\n",
       " ('nothing', 'B-NEG', 263),\n",
       " ('no', 'B-NEG', 288),\n",
       " ('not', 'B-NEG', 289),\n",
       " ('not', 'B-NEG', 289),\n",
       " ('neither', 'B-NEG', 294),\n",
       " ('Nothing', 'B-NEG', 296),\n",
       " ('not', 'B-NEG', 302),\n",
       " ('not', 'B-NEG', 308),\n",
       " ('not', 'B-NEG', 308),\n",
       " ('not', 'B-NEG', 321),\n",
       " ('not', 'B-NEG', 321),\n",
       " (\"n't\", 'B-NEG', 338),\n",
       " ('not', 'B-NEG', 341),\n",
       " (\"n't\", 'B-NEG', 360),\n",
       " ('not', 'B-NEG', 362),\n",
       " (\"n't\", 'B-NEG', 372),\n",
       " ('not', 'B-NEG', 376),\n",
       " ('no', 'B-NEG', 377),\n",
       " (\"n't\", 'B-NEG', 378),\n",
       " ('nor', 'B-NEG', 378),\n",
       " ('nor', 'B-NEG', 378),\n",
       " (\"n't\", 'B-NEG', 381),\n",
       " ('nor', 'B-NEG', 381),\n",
       " ('no', 'B-NEG', 382),\n",
       " (\"n't\", 'B-NEG', 383),\n",
       " ('never', 'B-NEG', 384),\n",
       " ('not', 'B-NEG', 384),\n",
       " ('not', 'B-NEG', 385),\n",
       " ('nothing', 'B-NEG', 393),\n",
       " ('nothing', 'B-NEG', 394),\n",
       " ('nothing', 'B-NEG', 396),\n",
       " ('Nothing', 'B-NEG', 398),\n",
       " ('not', 'B-NEG', 424),\n",
       " ('without', 'B-NEG', 427),\n",
       " ('without', 'B-NEG', 447),\n",
       " ('nothing', 'B-NEG', 456),\n",
       " ('no', 'B-NEG', 456),\n",
       " ('without', 'B-NEG', 457),\n",
       " ('no', 'B-NEG', 460),\n",
       " ('not', 'B-NEG', 469),\n",
       " (\"n't\", 'B-NEG', 476),\n",
       " ('never', 'B-NEG', 480),\n",
       " ('not', 'B-NEG', 481),\n",
       " (\"n't\", 'B-NEG', 492),\n",
       " ('not', 'B-NEG', 494),\n",
       " (\"n't\", 'B-NEG', 495),\n",
       " (\"n't\", 'B-NEG', 502),\n",
       " ('No', 'B-NEG', 503),\n",
       " ('no', 'B-NEG', 506),\n",
       " ('nothing', 'B-NEG', 510),\n",
       " (\"n't\", 'B-NEG', 512),\n",
       " (\"n't\", 'B-NEG', 512),\n",
       " (\"n't\", 'B-NEG', 517),\n",
       " (\"n't\", 'B-NEG', 520),\n",
       " ('not', 'B-NEG', 537),\n",
       " ('not', 'B-NEG', 541),\n",
       " ('not', 'B-NEG', 543),\n",
       " ('no', 'B-NEG', 571),\n",
       " ('not', 'B-NEG', 572),\n",
       " ('not', 'B-NEG', 572),\n",
       " (\"n't\", 'B-NEG', 578),\n",
       " ('no', 'B-NEG', 580),\n",
       " ('never', 'B-NEG', 583),\n",
       " ('not', 'B-NEG', 605),\n",
       " ('nothing', 'B-NEG', 612),\n",
       " ('nothing', 'B-NEG', 614),\n",
       " (\"n't\", 'B-NEG', 617),\n",
       " ('nothing', 'B-NEG', 618),\n",
       " ('not', 'B-NEG', 623),\n",
       " ('not', 'B-NEG', 628),\n",
       " (\"n't\", 'B-NEG', 645),\n",
       " ('no', 'B-NEG', 657),\n",
       " (\"n't\", 'B-NEG', 668),\n",
       " ('no', 'B-NEG', 693),\n",
       " ('no', 'B-NEG', 698),\n",
       " ('no', 'B-NEG', 698),\n",
       " ('not', 'B-NEG', 712),\n",
       " ('never', 'B-NEG', 713),\n",
       " ('never', 'B-NEG', 722),\n",
       " ('not', 'B-NEG', 736),\n",
       " ('not', 'B-NEG', 740),\n",
       " ('no', 'B-NEG', 741),\n",
       " ('not', 'B-NEG', 747),\n",
       " ('never', 'B-NEG', 747),\n",
       " ('not', 'B-NEG', 751),\n",
       " ('No', 'B-NEG', 759),\n",
       " ('no', 'B-NEG', 759),\n",
       " ('no', 'B-NEG', 762),\n",
       " ('never', 'B-NEG', 764),\n",
       " ('not', 'B-NEG', 768),\n",
       " ('not', 'B-NEG', 771),\n",
       " ('nothing', 'B-NEG', 784),\n",
       " ('without', 'B-NEG', 784)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of tuples of correctly predicted lexical negation cues and their labels + new sentence numbers\n",
    "b_neg_lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b354d995-22f7-442f-b482-9289f4fbd60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sentences for all correctly predicted lexical negations and put in list \n",
    "l = []\n",
    "for token, label, sentnr in b_neg_lex:\n",
    "    l.append(sentnr)\n",
    "\n",
    "\n",
    "b_neg_lex_sentences = []\n",
    "\n",
    "for item in l:\n",
    "    i = 0\n",
    "    s = []\n",
    "    for nr in sentnrs:\n",
    "        if nr == item:\n",
    "            s.append(tokenlist[i])\n",
    "        i += 1\n",
    "    b_neg_lex_sentences.append(s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3f33542-368a-4fe5-892e-10d2de986aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('no', 'B-NEG', 4)\n",
      "['He', 'made', 'no', 'remark', ',', 'but', 'the', 'matter', 'remained', 'in', 'his', 'thoughts', ',', 'for', 'he', 'stood', 'in', 'front', 'of', 'the', 'fire', 'afterwards', 'with', 'a', 'thoughtful', 'face', ',', 'smoking', 'his', 'pipe', ',', 'and', 'casting', 'an', 'occasional', 'glance', 'at', 'the', 'message', '.']\n"
     ]
    }
   ],
   "source": [
    "# now the lists of sentences and lexical negation cues correspond, and we can use it to analyse the context of the errors and matches.\n",
    "print(b_neg_lex[0])\n",
    "print(b_neg_lex_sentences[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
